Lmod: loading gcc 8.5.0 
Lmod: loading python 3.10.10 
Lmod: loading cuda 11.8 
Lmod: loading cuDNN 8.8.1 
/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[W socket.cpp:426] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:426] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:426] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:426] [c10d] The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use).
[E socket.cpp:462] [c10d] The server socket has failed to listen on any local network address.
[W socket.cpp:426] [c10d] The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use).
[E socket.cpp:462] [c10d] The server socket has failed to listen on any local network address.
Traceback (most recent call last):
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/runpy.py", line 196, in _run_module_as_main
Traceback (most recent call last):
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/runpy.py", line 86, in _run_code
    return _run_code(code, main_globals, None,
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launch.py", line 196, in <module>
    exec(code, run_globals)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launch.py", line 196, in <module>
    main()
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launch.py", line 192, in main
    main()
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launch.py", line 192, in main
    launch(args)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launch.py", line 177, in launch
    launch(args)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launch.py", line 177, in launch
    run(args)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    run(args)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    elastic_launch(
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 241, in launch_agent
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 241, in launch_agent
    result = agent.run()
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = agent.run()
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 723, in run
    result = f(*args, **kwargs)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 723, in run
    result = self._invoke_run(role)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 858, in _invoke_run
    result = self._invoke_run(role)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 858, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    self._initialize_workers(self._worker_group)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 692, in _initialize_workers
    result = f(*args, **kwargs)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 692, in _initialize_workers
    self._rendezvous(worker_group)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    self._rendezvous(worker_group)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 546, in _rendezvous
    result = f(*args, **kwargs)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 546, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 55, in next_rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 55, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol). The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use).
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol). The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use).
/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[W socket.cpp:426] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:426] [c10d] The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use).
[E socket.cpp:462] [c10d] The server socket has failed to listen on any local network address.
Traceback (most recent call last):
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launch.py", line 196, in <module>
    main()
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launch.py", line 192, in main
    launch(args)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launch.py", line 177, in launch
    run(args)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 241, in launch_agent
    result = agent.run()
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 723, in run
    result = self._invoke_run(role)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 858, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 692, in _initialize_workers
    self._rendezvous(worker_group)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 546, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 55, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol). The server socket has failed to bind to 0.0.0.0:29500 (errno: 98 - Address already in use).
srun: error: gvqc0001: tasks 0,2-3: Exited with exit code 1
wandb: Currently logged in as: bayer (few_shot). Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/mb14sola/.netrc
wandb: Currently logged in as: bayer (few_shot). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: bayer (few_shot). Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/mb14sola/.netrc
wandb: Appending key for api.wandb.ai to your netrc file: /home/mb14sola/.netrc
wandb: Currently logged in as: bayer (few_shot). Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/mb14sola/.netrc
The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.
The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.
The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.
The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s]
There was a problem when trying to move your cache:

  File "/home/mb14sola/.local/lib/python3.10/site-packages/transformers/utils/hub.py", line 1106, in <module>
    move_cache(TRANSFORMERS_CACHE, TRANSFORMERS_CACHE)

  File "/home/mb14sola/.local/lib/python3.10/site-packages/transformers/utils/hub.py", line 1070, in move_cache
    move_to_new_cache(

  File "/home/mb14sola/.local/lib/python3.10/site-packages/transformers/utils/hub.py", line 1023, in move_to_new_cache
    shutil.move(file, blob_path)

  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/shutil.py", line 836, in move
    copy_function(src, real_dst)

  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/shutil.py", line 434, in copy2
    copyfile(src, dst, follow_symlinks=follow_symlinks)

  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/shutil.py", line 254, in copyfile
    with open(src, 'rb') as fsrc:

FileNotFoundError: [Errno 2] No such file or directory: '/work/projects/project02060/.cache/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e'

Please file an issue at https://github.com/huggingface/transformers/issues/new/choose and copy paste this whole message and we will do our best to help.
There was a problem when trying to move your cache:

  File "/home/mb14sola/.local/lib/python3.10/site-packages/transformers/utils/hub.py", line 1106, in <module>
    move_cache(TRANSFORMERS_CACHE, TRANSFORMERS_CACHE)

  File "/home/mb14sola/.local/lib/python3.10/site-packages/transformers/utils/hub.py", line 1070, in move_cache
    move_to_new_cache(

  File "/home/mb14sola/.local/lib/python3.10/site-packages/transformers/utils/hub.py", line 1023, in move_to_new_cache
    shutil.move(file, blob_path)

  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/shutil.py", line 836, in move
    copy_function(src, real_dst)

  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/shutil.py", line 434, in copy2
    copyfile(src, dst, follow_symlinks=follow_symlinks)

  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/shutil.py", line 254, in copyfile
    with open(src, 'rb') as fsrc:

FileNotFoundError: [Errno 2] No such file or directory: '/work/projects/project02060/.cache/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e'

Please file an issue at https://github.com/huggingface/transformers/issues/new/choose and copy paste this whole message and we will do our best to help.
There was a problem when trying to move your cache:

  File "/home/mb14sola/.local/lib/python3.10/site-packages/transformers/utils/hub.py", line 1106, in <module>
    move_cache(TRANSFORMERS_CACHE, TRANSFORMERS_CACHE)

  File "/home/mb14sola/.local/lib/python3.10/site-packages/transformers/utils/hub.py", line 1070, in move_cache
    move_to_new_cache(

  File "/home/mb14sola/.local/lib/python3.10/site-packages/transformers/utils/hub.py", line 1023, in move_to_new_cache
    shutil.move(file, blob_path)

  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/shutil.py", line 836, in move
    copy_function(src, real_dst)

  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/shutil.py", line 434, in copy2
    copyfile(src, dst, follow_symlinks=follow_symlinks)

  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/shutil.py", line 254, in copyfile
    with open(src, 'rb') as fsrc:

FileNotFoundError: [Errno 2] No such file or directory: '/work/projects/project02060/.cache/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e'

Please file an issue at https://github.com/huggingface/transformers/issues/new/choose and copy paste this whole message and we will do our best to help.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.76it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.76it/s]
2023-04-13 08:48:09.563698: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-04-13 08:48:09.563702: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-04-13 08:48:09.563693: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-04-13 08:48:09.563697: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-04-13 08:48:10.100146: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-04-13 08:48:10.100146: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-04-13 08:48:10.100146: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-04-13 08:48:10.100145: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-04-13 08:48:15.373131: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-04-13 08:48:15.373134: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-04-13 08:48:15.373134: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-04-13 08:48:15.373137: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
wandb: Tracking run with wandb version 0.14.2
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /work/projects/project02060/CyBERT/wandb/run-20230413_084826-5jkg3dsw
wandb: Run `wandb offline` to turn off syncing.
wandb: Run data is saved locally in /work/projects/project02060/CyBERT/wandb/run-20230413_084826-somwk89l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-cosmos-441
wandb: Syncing run glamorous-oath-441
wandb: â­ï¸ View project at https://wandb.ai/few_shot/CyBERT
wandb: ðŸš€ View run at https://wandb.ai/few_shot/CyBERT/runs/somwk89l
wandb: â­ï¸ View project at https://wandb.ai/few_shot/CyBERT
wandb: ðŸš€ View run at https://wandb.ai/few_shot/CyBERT/runs/5jkg3dsw
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /work/projects/project02060/CyBERT/wandb/run-20230413_084826-kubqb4lm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-brook-443
wandb: â­ï¸ View project at https://wandb.ai/few_shot/CyBERT
wandb: ðŸš€ View run at https://wandb.ai/few_shot/CyBERT/runs/kubqb4lm
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /work/projects/project02060/CyBERT/wandb/run-20230413_084826-wv5i39ux
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-plasma-443
wandb: â­ï¸ View project at https://wandb.ai/few_shot/CyBERT
wandb: ðŸš€ View run at https://wandb.ai/few_shot/CyBERT/runs/wv5i39ux
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
Traceback (most recent call last):
  File "/work/projects/project02060/CyBERT/cybert/code/run_mlm.py", line 453, in <module>
    main()
  File "/work/projects/project02060/CyBERT/cybert/code/run_mlm.py", line 182, in main
    model_args, data_args, training_args = parser.parse_args_into_dataclasses()
  File "/home/mb14sola/.local/lib/python3.10/site-packages/transformers/hf_argparser.py", line 341, in parse_args_into_dataclasses
    raise ValueError(f"Some specified arguments are not used by the HfArgumentParser: {remaining_args}")
ValueError: Some specified arguments are not used by the HfArgumentParser: ['--local-rank=3']
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
Traceback (most recent call last):
  File "/work/projects/project02060/CyBERT/cybert/code/run_mlm.py", line 453, in <module>
    main()
  File "/work/projects/project02060/CyBERT/cybert/code/run_mlm.py", line 182, in main
    model_args, data_args, training_args = parser.parse_args_into_dataclasses()
  File "/home/mb14sola/.local/lib/python3.10/site-packages/transformers/hf_argparser.py", line 341, in parse_args_into_dataclasses
    raise ValueError(f"Some specified arguments are not used by the HfArgumentParser: {remaining_args}")
Traceback (most recent call last):
ValueError: Some specified arguments are not used by the HfArgumentParser: ['--local-rank=2']
Traceback (most recent call last):
  File "/work/projects/project02060/CyBERT/cybert/code/run_mlm.py", line 453, in <module>
    main()
  File "/work/projects/project02060/CyBERT/cybert/code/run_mlm.py", line 453, in <module>
    main()
  File "/work/projects/project02060/CyBERT/cybert/code/run_mlm.py", line 182, in main
    model_args, data_args, training_args = parser.parse_args_into_dataclasses()
  File "/work/projects/project02060/CyBERT/cybert/code/run_mlm.py", line 182, in main
    model_args, data_args, training_args = parser.parse_args_into_dataclasses()
  File "/home/mb14sola/.local/lib/python3.10/site-packages/transformers/hf_argparser.py", line 341, in parse_args_into_dataclasses
    raise ValueError(f"Some specified arguments are not used by the HfArgumentParser: {remaining_args}")
  File "/home/mb14sola/.local/lib/python3.10/site-packages/transformers/hf_argparser.py", line 341, in parse_args_into_dataclasses
    raise ValueError(f"Some specified arguments are not used by the HfArgumentParser: {remaining_args}")
ValueError: Some specified arguments are not used by the HfArgumentParser: ['--local-rank=0']
ValueError: Some specified arguments are not used by the HfArgumentParser: ['--local-rank=1']
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: ðŸš€ View run cerulean-cosmos-441 at: https://wandb.ai/few_shot/CyBERT/runs/somwk89l
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230413_084826-somwk89l/logs
wandb: ðŸš€ View run hearty-plasma-443 at: https://wandb.ai/few_shot/CyBERT/runs/wv5i39ux
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230413_084826-wv5i39ux/logs
wandb: ðŸš€ View run glamorous-oath-441 at: https://wandb.ai/few_shot/CyBERT/runs/5jkg3dsw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230413_084826-5jkg3dsw/logs
wandb: ðŸš€ View run vivid-brook-443 at: https://wandb.ai/few_shot/CyBERT/runs/kubqb4lm
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230413_084826-kubqb4lm/logs
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 540794) of binary: /shared/apps/.gcc/8.5/python/3.10.10/bin/python
Traceback (most recent call last):
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launch.py", line 196, in <module>
    main()
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launch.py", line 192, in main
    launch(args)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launch.py", line 177, in launch
    run(args)
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/shared/apps/.gcc/8.5/python/3.10.10/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
cybert/code/run_mlm.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-04-13_08:48:37
  host      : gvqc0001.lcluster
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 540795)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-04-13_08:48:37
  host      : gvqc0001.lcluster
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 540796)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-04-13_08:48:37
  host      : gvqc0001.lcluster
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 540797)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-04-13_08:48:37
  host      : gvqc0001.lcluster
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 540794)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
srun: error: gvqc0001: task 1: Exited with exit code 1
