{"data": "Traceback (most recent call last):\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/jiant/utils/zlog.py\", line 39, in log_context\n    yield self\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/jiant/proj/main/runscript.py\", line 171, in run_loop\n    metarunner.run_train_loop()\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/jiant/shared/metarunner.py\", line 38, in run_train_loop\n    for _ in self.yield_train_step():\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/jiant/proj/main/metarunner.py\", line 109, in yield_train_step\n    for train_state in train_iterator:\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/jiant/proj/main/runner.py\", line 75, in run_train_context\n    self.run_train_step(\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/jiant/proj/main/runner.py\", line 104, in run_train_step\n    model_output = wrap_jiant_forward(\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/jiant/proj/main/modeling/primary.py\", line 107, in wrap_jiant_forward\n    jiant_model(\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/jiant/proj/main/modeling/primary.py\", line 77, in forward\n    return taskmodel(\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/jiant/proj/main/modeling/taskmodels.py\", line 81, in forward\n    encoder_output = self.encoder.encode(\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/jiant/proj/main/modeling/primary.py\", line 207, in encode\n    output = self.forward(\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 1020, in forward\n    encoder_outputs = self.encoder(\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 610, in forward\n    layer_outputs = layer_module(\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 495, in forward\n    self_attention_outputs = self.attention(\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 425, in forward\n    self_outputs = self.self(\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 323, in forward\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.61 GiB total capacity; 13.86 GiB already allocated; 15.12 MiB free; 13.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n", "TIMESTAMP": 1684311492.513416}
