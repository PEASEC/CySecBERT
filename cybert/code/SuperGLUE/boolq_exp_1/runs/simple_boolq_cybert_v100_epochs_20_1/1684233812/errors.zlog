{"data": "Traceback (most recent call last):\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/jiant/utils/zlog.py\", line 39, in log_context\n    yield self\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/jiant/proj/main/runscript.py\", line 171, in run_loop\n    metarunner.run_train_loop()\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/jiant/shared/metarunner.py\", line 38, in run_train_loop\n    for _ in self.yield_train_step():\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/jiant/proj/main/metarunner.py\", line 109, in yield_train_step\n    for train_state in train_iterator:\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/jiant/proj/main/runner.py\", line 75, in run_train_context\n    self.run_train_step(\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/jiant/proj/main/runner.py\", line 104, in run_train_step\n    model_output = wrap_jiant_forward(\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/jiant/proj/main/modeling/primary.py\", line 107, in wrap_jiant_forward\n    jiant_model(\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/jiant/proj/main/modeling/primary.py\", line 77, in forward\n    return taskmodel(\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/jiant/proj/main/modeling/taskmodels.py\", line 81, in forward\n    encoder_output = self.encoder.encode(\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/jiant/proj/main/modeling/primary.py\", line 207, in encode\n    output = self.forward(\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 1020, in forward\n    encoder_outputs = self.encoder(\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 610, in forward\n    layer_outputs = layer_module(\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 537, in forward\n    layer_output = apply_chunking_to_forward(\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/transformers/pytorch_utils.py\", line 236, in apply_chunking_to_forward\n    return forward_fn(*input_tensors)\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 550, in feed_forward_chunk\n    layer_output = self.output(intermediate_output, attention_output)\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 463, in forward\n    hidden_states = self.dropout(hidden_states)\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py\", line 59, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n  File \"/home/mb14sola/.local/lib/python3.10/site-packages/torch/nn/functional.py\", line 1252, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.61 GiB total capacity; 13.63 GiB already allocated; 43.12 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n", "TIMESTAMP": 1684233827.108343}
