{"data": "Traceback (most recent call last):\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/jiant/utils/zlog.py\", line 39, in log_context\n    yield self\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/jiant/proj/main/runscript.py\", line 171, in run_loop\n    metarunner.run_train_loop()\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/jiant/shared/metarunner.py\", line 38, in run_train_loop\n    for _ in self.yield_train_step():\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/jiant/proj/main/metarunner.py\", line 109, in yield_train_step\n    for train_state in train_iterator:\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/jiant/proj/main/runner.py\", line 76, in run_train_context\n    train_dataloader_dict=train_dataloader_dict, train_state=train_state\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/jiant/proj/main/runner.py\", line 105, in run_train_step\n    jiant_model=self.jiant_model, batch=batch, task=task, compute_loss=True,\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/jiant/proj/main/modeling/primary.py\", line 108, in wrap_jiant_forward\n    batch=batch.to_dict() if is_multi_gpu else batch, task=task, compute_loss=compute_loss,\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/jiant/proj/main/modeling/primary.py\", line 78, in forward\n    batch=batch, tokenizer=self.tokenizer, compute_loss=compute_loss,\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/jiant/proj/main/modeling/taskmodels.py\", line 82, in forward\n    input_ids=batch.input_ids, segment_ids=batch.segment_ids, input_mask=batch.input_mask,\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/jiant/proj/main/modeling/primary.py\", line 211, in encode\n    output_hidden_states=output_hidden_states,\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 981, in forward\n    return_dict=return_dict,\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 575, in forward\n    output_attentions,\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 461, in forward\n    past_key_value=self_attn_past_key_value,\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 394, in forward\n    output_attentions,\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/mb14sola/.conda/envs/jiant_py37/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 309, in forward\n    attention_scores = attention_scores / math.sqrt(self.attention_head_size)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.56 GiB total capacity; 13.39 GiB already allocated; 92.50 MiB free; 13.45 GiB reserved in total by PyTorch)\n", "TIMESTAMP": 1652787146.994177}
